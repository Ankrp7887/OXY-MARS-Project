{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: selenium in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (35.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
      "Requirement already satisfied: webdriver_manager in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: crayons in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver_manager) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver_manager) (2.26.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from crayons->webdriver_manager) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver_manager) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver_manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver_manager) (2.0.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: boltons in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (21.0.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.6.4)\n",
      "Requirement already satisfied: boltons in c:\\users\\ap788\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (21.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install selenium\n",
    "!pip install webdriver_manager\n",
    "!pip install pandas\n",
    "!pip install boltons\n",
    "!pip install lxml\n",
    "!pip install boltons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from boltons import iterutils   \n",
    "from lxml import etree \n",
    "import requests   \n",
    "import warnings     \n",
    "import time\n",
    "import re  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables containing perticular job details\n",
    "\n",
    "\n",
    "#'Enter Main Company link(Having 25 entries each) : \n",
    "complink = ['https://jobs.gaijinpot.com/job/index/company_id/5/lang/en']\n",
    "\n",
    "#'Enter .CSV filename. ie, short Company name :       \n",
    "filename = 'altia.csv'     \n",
    "\n",
    "#'Enter given email address :                                                                                                                                       \n",
    "email_address = 'altiacentral@sunisbrite.com'                            \n",
    "\n",
    "#'Enter Company name :                                                                                                                      \n",
    "company_name = 'Altia Central Co.' \n",
    "\n",
    "#'Check total number of jobs and enter here :\n",
    "total_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating total no. of pages need to scrap\n",
    "string = complink[0]\n",
    "loc = string.find('jobs-career')\n",
    "loc = loc + 11\n",
    "last_page = 1\n",
    "if total_jobs > 25:\n",
    "    if total_jobs % 25 == 0:\n",
    "        x = int(total_jobs//25)\n",
    "    else:\n",
    "        x = int(total_jobs//25)\n",
    "        x = x+1\n",
    "\n",
    "    for i in range(2, x+1):\n",
    "        page = complink[0][0:loc] + f'-{i}' + complink[0][loc:]\n",
    "        complink.append(page)\n",
    "        last_page = i\n",
    "#print(complink)\n",
    "#print(complink[0:last_page])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definiotions of all required functions\n",
    "\n",
    "def identify_job_sector(x):\n",
    "    if 'Human' in x or 'Recruitment' in x or 'Human Resources' in x or 'Admin' in x:\n",
    "        x = 'HR Jobs'\n",
    "    elif 'Digital Marketing' in x or 'Marketing & Communications' in x or 'Marketing Research & Analysis' in x or 'Advertising' in x or 'Buyer' in x:\n",
    "        x = 'Marketing Jobs'  \n",
    "    elif 'Health' in x or 'Hospitals' in x or 'Healthcare' in x or 'Diagnostics' in x or 'Personal Care' in x:\n",
    "        x = 'Health Care Jobs'\n",
    "    elif 'Customer Service' in x:\n",
    "        x = 'Consultant Jobs' \n",
    "    elif 'Finance & Accounts' in x:\n",
    "        x = 'Accounting Jobs'\n",
    "    elif 'Pharmaceutical' in x:\n",
    "        x = 'Pharma Jobs'\n",
    "    elif 'Application' in x:\n",
    "        x = 'Application Programming Jobs'\n",
    "    elif 'Product Management' in x:\n",
    "        x = 'Maintenance Jobs'\n",
    "    elif 'Oil & Gas' in x or 'Engineering - Electronics' in x or 'Engineering - Chemical' in x or 'Manufacturing' in x:\n",
    "        x = 'Engineering'\n",
    "    elif 'Retail Chains' in x:\n",
    "        x = 'Sales'\n",
    "    elif 'Telecom Software' in x:\n",
    "        x = 'Telecom Software Jobs'\n",
    "    elif 'Banking' in x:\n",
    "        x = 'Bank Jobs'\n",
    "    elif 'System' in x:\n",
    "        x = 'System Programming Jobs'\n",
    "    elif 'Site' in x:\n",
    "        x = 'Site Engineering Jobs'\n",
    "    elif 'Network' in x:\n",
    "        x = 'Network administrator Jobs'\n",
    "    elif 'Interior' in x or 'Architecture' in x:\n",
    "        x = 'Interior Design Jobs'\n",
    "    elif 'IT' in x or 'Information' in x or 'IT- Hardware' in x:\n",
    "        x = 'IT Jobs'\n",
    "    elif 'Export' in x:\n",
    "        x = 'Export Import'\n",
    "    elif 'Graphic' in x or 'Arts' in x:\n",
    "        x = 'Graphic Designer Jobs'\n",
    "    elif 'Hardwer' in x:\n",
    "        x = 'Hardwer & Networking Jobs'\n",
    "    elif 'BPO' in x:\n",
    "       x = 'BPO / Call Centre'\n",
    "    elif 'Business' in x:\n",
    "        x = 'Business Intelligence Jobs'\n",
    "    elif 'Client' in x:\n",
    "        x = 'Client Server Jobs'\n",
    "    elif 'Content' in x or 'Journalism' in x:\n",
    "        x = 'Content Writing'\n",
    "    elif 'Corporate' in x:\n",
    "        x = 'Corporate Planning Jobs'\n",
    "    elif 'Education' in x:\n",
    "        x = 'Education Training'  \n",
    "    elif  'Marine Services' in x:\n",
    "        x = 'Merchandiser'\n",
    "    elif 'Hotels' in x:\n",
    "        x = 'Hotel Jobs'\n",
    "    elif 'Accounting' in x or 'Airline' in x or 'Automobile' in x or 'Bank' in x or 'Analytics' in x or 'Consultant' in x or 'DBA' in x or 'Ecommerce' in x or 'EDP' in x:\n",
    "        x = x\n",
    "    elif 'Film' in x or 'Hotel' in x or 'Legal' in x or 'Logistics' in x or 'Pharma' in x:\n",
    "        x = x\n",
    "    elif 'Mainframe' in x or 'Maintenance' in x or 'Marketing' in x or 'Middleware' in x or 'Mobile' in x or 'Packaging' in x or 'Pharma' in x or 'Secretary' in x:\n",
    "        x = x\n",
    "    elif 'Security' in x or 'Shipping' in x or 'Testing' in x or 'VLSI' in x or 'ERP' in x:\n",
    "        x = x\n",
    "    else:\n",
    "        x = 'IT Jobs'\n",
    "    \n",
    "    return x\n",
    "\n",
    "indusrty =  ['Development', 'Management', 'Finance', 'Html Document', 'Seo', 'Banking',\n",
    "            'Graphic Design', 'Php Department', 'Information Technology']\n",
    "def identify_industry(y):\n",
    "    if y in industry:\n",
    "        return y\n",
    "    elif y == 'Education':\n",
    "        y = 'Development'\n",
    "    else:\n",
    "        y = 'Information Technology'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                          ***Freshly(from 1st page) Scraping Should be done from this cell....***\n",
    "\n",
    "\n",
    "#temp list to store scraped data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 ***Ranged Scraping Should be done from this cell, if you given range for scraping.\n",
    "#                                                        ie, you scraped some pages and now startig scraping from some page, other than 1st....***\n",
    "\n",
    "\n",
    "\n",
    "#Enter the Page where on which got error...\n",
    "#Defaultly 'scraping_start_page = 1'\n",
    "scraping_start_page = 1\n",
    "#last_page = 10                              #last page for scraping excluding given page number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Driver [C:\\Users\\ap788\\.wdm\\drivers\\edgedriver\\win64\\95.0.1020.53\\msedgedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page - 1\n",
      "<div class=\"card card--premium\">\n",
      "<div class=\"card-header\">\n",
      "<h1 class=\"card-heading text-xlarge\">Enthusiastic Public School ALT in Japan – Overseas Applicants</h1>\n",
      "</div>\n",
      "<div class=\"card-item\">\n",
      "<div class=\"media visible-xs\">\n",
      "<div class=\"media-left\">\n",
      "<img alt=\"Altia Central (株式会社 アルティアセントラル)\" class=\"img-thumbnail media-object\" height=\"60\" src=\"https://jobs.gaijinpot.com/logo/5/138.thumbnail.png\" width=\"60\"/>\n",
      "</div>\n",
      "<div class=\"media-body\">\n",
      "<h4 class=\"media-heading text-regular\">Altia Central (株式会社 アルティアセントラル)</h4>\n",
      "</div>\n",
      "</div>\n",
      "<span class=\"hr hr--small visible-xs\"></span>\n",
      "<dl class=\"mb-0\">\n",
      "<dt class=\"hidden-xs\">Company</dt>\n",
      "<dd class=\"hidden-xs\">Altia Central (株式会社 アルティアセントラル)\t\t\t\t</dd>\n",
      "<dt>Job ID</dt>\n",
      "<dd>142912</dd>\n",
      "<dt>Location</dt>\n",
      "<dd>Aichi, Japan</dd>\n",
      "<dt>Post date</dt>\n",
      "<dd>Oct 21, 2021</dd>\n",
      "<dt>Industry</dt>\n",
      "<dd>Education / Teaching</dd>\n",
      "<dt>Function</dt>\n",
      "<dd>Other Education / Teaching, Training</dd>\n",
      "<dt>Work Type</dt>\n",
      "<dd>Full Time\t\t\t\t\t/ Experienced (Non-Manager)\t\t\t\t</dd>\n",
      "<dt>Salary</dt>\n",
      "<dd>¥240,000 ~ ¥255,000 / Month\t\t\t\t\t\t\t\t\t\t\t<ul class=\"list-unindented mb-0\">\n",
      "<li>Depending on qualifications and experience.</li>\n",
      "</ul>\n",
      "</dd>\n",
      "</dl>\n",
      "</div>\n",
      "<div class=\"card-item card-item--small\">\n",
      "<h3 class=\"card-heading text-uppercase\">Requirements</h3>\n",
      "</div>\n",
      "<div class=\"card-item\">\n",
      "<ul class=\"list mb-0\">\n",
      "<li>English: Native level</li><li>Japanese: Conversational</li><li>Prefer to have prior ESL, eikaiwa, or ALT experience,  or at the very least, some previous experience teaching young learners.</li><li>Visa sponsorship available</li> </ul>\n",
      "</div>\n",
      "<div class=\"card-item card-item--small\">\n",
      "<h3 class=\"card-heading text-uppercase\">Description</h3>\n",
      "</div>\n",
      "<p class=\"card-item\">ALTIA CENTRAL is once again accepting applications from all overseas candidates to join our team of fantastic ALTs from April 2022. If you would like to live and work in Japan, or make a return to Japan and work with one of the most reputable and successful companies in the ALT industry, then please apply now.  <br/>\n",
      "<br/>\n",
      "Please note that the border restrictions to enter Japan are constantly changing and we do not know what the conditions will be like as we approach April.  However, as of this posting, we do know it is possible, although with a lot more difficulty, to bring people over.  In addition to this, we are still working with a backlog of previous applicants, which will make this a much more competitive year.<br/>\n",
      "<br/>\n",
      "---About The Position---<br/>\n",
      "<br/>\n",
      "▲ Full Time<br/>\n",
      "▲ Yearly salary + annual bonus:  ¥3,000,000<br/>\n",
      "▲ Positions may include: junior high, elementary schools and kindergarten<br/>\n",
      "▲ Driving may be required <br/>\n",
      "▲ Health Insurance: Shakai Hoken (includes health and pension) or Kokumin Hoken, depending on placement<br/>\n",
      "<br/>\n",
      "Our contracts are largely based in central Japan, mostly in Aichi, Gifu, and Shizuoka prefectures; with a strong presence in Okayama and Hiroshima; a number of contracts in Shiga, Mie, Nagano, and Fukui; as well as a limited number of positions in Osaka, Kyoto and the greater Kansai area. If you are focused on going to Osaka and Osaka only, we will most likely not be able to help you out.  Please note that we DO NOT have anything in the greater Tokyo Area.<br/>\n",
      "<br/>\n",
      "---What We Offer---<br/>\n",
      "<br/>\n",
      "We want to support your growth and development to become a great ALT. The skills and experiences you will gain with us, will greatly benefit you in various ways for your future career. But don’t take our word for it, see for yourself what others say on sites like Glassdoor and Reddit. <br/>\n",
      "<br/>\n",
      "---Benefits---<br/>\n",
      "<br/>\n",
      "▲ Full salary every month, no prorated months, paid on-time every time<br/>\n",
      "▲ Outstanding and reliable support from Supervisors and staff<br/>\n",
      "▲ Comprehensive benefits package with paid Annual Leave days<br/>\n",
      "▲ Housing support:  we pay key money and deposit for company sponsored apartments so you don’t have to <br/>\n",
      "▲ Reimbursements:  public transportation, bicycle, and more <br/>\n",
      "▲ Driving support:  we pay for the car lease and offer a variety of driving plans to suit your needs (up to and including fully paid plans where we pay gas, insurance, maintenance, etc.), and more <br/>\n",
      "▲ Industry-leading training:  tailored to your needs, taught by highly skilled trainers, hands-on, ongoing year-round, and professional development for your future career <br/>\n",
      "▲ Resources and materials:  Access to top-quality educational resources anytime through our members website including storyboards, flashcards, songs, example lesson plans and more <br/>\n",
      "▲ Visa Sponsorship<br/>\n",
      "<br/>\n",
      "---Key Qualifications---<br/>\n",
      "<br/>\n",
      "▲Native English speaker <br/>\n",
      "▲Bachelor's degree (or higher)<br/>\n",
      "▲ Engaging, enthusiastic, and motivated to provide a positive communicative experience for students<br/>\n",
      "▲ Flexible, culturally sensitive, and eager to live in Japan for a minimum of one year<br/>\n",
      "▲ Previous teaching experience ranging from ALT to ESL tutoring within Japan or in other countries<br/>\n",
      "▲Must have at least a basic level of Japanese with a conversational level being strongly preferred<br/>\n",
      "▲Previous time spent studying or working in Japan is preferred<br/>\n",
      "▲As many ALT positions do require driving, applicants who can or would be able to drive in Japan on either a Japanese license or International Driving Permit are preferred<br/>\n",
      "<br/>\n",
      "---The Role---<br/>\n",
      "<br/>\n",
      "An ALT’s work in public schools centers around creating positive interactions with the students both inside and outside the classroom and helping to provide enjoyable and energetic lessons. ALTs also develop and maintain a positive and supportive professional relationship with Japanese teachers by assisting with various tasks during the school year. ALTs will experience prolonged periods of standing, walking, and stair climbing. ALTs will also be encouraged to perform high energy movements such as running and playing with students. To help you find success in this role, our ALTs are frequently evaluated throughout the year based on their lesson’s clarity, how supportive they are, and the overall atmosphere they help to create in the classroom. We are dedicated to helping our ALTs grow and improve for their future success by offering ongoing advice, feedback, and more.<br/>\n",
      "<br/>\n",
      "Working as an ALT is a great opportunity to improve your Japanese language ability, experience and appreciate cultural differences, and most importantly, to be positively involved with the development and well-being of Japanese students. <br/>\n",
      "<br/>\n",
      "<br/>\n",
      "---The Application Process---<br/>\n",
      "<br/>\n",
      "Once we receive your resume and cover letter, we will only reply to qualified applicants via email. Those that pass our subsequent screening questionnaire will then be invited to an interview. Unfortunately, due to the current conditions caused by the coronavirus, we will be forgoing our normal face-to-face interviews and instead temporarily resort to a Skype-only system for all applicants.<br/>\n",
      "<br/>\n",
      "Successful applicants will need to be available for a full 4-day Orientation/Training session before starting in school. If you are interested in applying, please visit our Recruiting website for further details about ALTIA CENTRAL.<br/>\n",
      "</p>\n",
      "</div>\n",
      "13\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16336/2879588217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Japan.*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mjob_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'card-heading text-xlarge'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mindustry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob_details\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindustry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2252\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2253\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2254\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "#Scraping data from Job URL\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "scraping_start_page = scraping_start_page - 1\n",
    "data_length = 0\n",
    "\n",
    "\n",
    "for lnk in complink[scraping_start_page:last_page]:     \n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Edge(EdgeChromiumDriverManager().install())                     #|If you want to work with chromedriver, simply comment this line\n",
    "        #driver = webdriver.Chrome(ChromeDriverManager().install())                        #|If you want to work with chromedriver, simply remove comment symbol(#) of this line\n",
    "    except:\n",
    "        print('Your Connection is Lost')\n",
    "        print('Exicution Trminated')\n",
    "        break\n",
    "\n",
    "    driver.minimize_window()\n",
    "\n",
    "    page = complink.index(lnk) + 1\n",
    "    print(f'Page - {page}')\n",
    "    monsterindia_responce_checker_out = 0\n",
    "    monsterindia_responce_checker_in = 0\n",
    "\n",
    "    try:\n",
    "        driver.get(lnk)\n",
    "    except WebDriverException:\n",
    "        print(f\"MonsterIndia Not Responding, Checked {i+1} time...(After 3rd time exicution will be trminated)\")\n",
    "        monsterindia_responce_checker_out = monsterindia_responce_checker_out + 1\n",
    "    if monsterindia_responce_checker_out >= 1:\n",
    "        print('Exicution Trminated')\n",
    "        break\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    resp = driver.page_source\n",
    "    soup = BeautifulSoup(resp, 'lxml')\n",
    "    link_list=set()\n",
    "    for link in soup.find_all('h3', class_ = 'card-heading mb-5'):\n",
    "        link_list.add(link.a['href'])\n",
    "\n",
    "    for link in link_list:\n",
    "        try: \n",
    "            driver.get('https://jobs.gaijinpot.com' + link)\n",
    "        except:\n",
    "            print(\"MonsterIndia.com Not Responding. Terminating cell exicution...\")\n",
    "            monsterindia_responce_checker_in = monsterindia_responce_checker_in + 1\n",
    "            break\n",
    "\n",
    "        resp_info = driver.page_source\n",
    "        soup_info = BeautifulSoup(resp_info, 'html.parser')\n",
    "        job_details = soup_info.find('div', class_ = 'card card--premium')\n",
    "\n",
    "        print(len(job_details))\n",
    "        #company_name = job_details.find('dd', class_ = \"hidden-xs\").text.strip() # company name\n",
    "        location = job_details.find('dd', text=re.compile('Japan.*')).text  \n",
    "        job_title = job_details.find('h1', class_ = 'card-heading text-xlarge').text\n",
    "        industry = job_details.find_all(\"dt\")[0].text\n",
    "\n",
    "        print(industry)\n",
    "        for job_details in job_details:\n",
    "            for k in range(10):\n",
    "                print(job_details.find_all(\"dt\")[k].text)\n",
    "        #         if job_details.find_all(\"dt\")[k].text == 'Company':\n",
    "        #             company_name = job_details.find_all(\"dd\")[k].text\n",
    "        #             print(company_name)           \n",
    "        #         industry = job_details.find_all(\"dd\")[4].text.split(' / ')[0]\n",
    "        #         job_sector = job_details.find_all(\"dd\")[5].text.split(' / ')[0]\n",
    "        #         job_type = job_details.find_all(\"dd\")[6].text.split(' / ')[0].split('/')[0].strip()\n",
    "        #         salary = job_details.find_all(\"dd\")[7].text.replace(',','').split('/')[0].replace('¥', '').replace(' ','').split('~')\n",
    "        #         salary_type = job_details.find_all(\"dd\")[7].text.replace(',','').split('/')[1][:11].strip()\n",
    "        if salary_type == 'Month' or salary_type == 'Year' or salary_type == 'Hour' or salary_type == 'Week':\n",
    "            min_salary = salary[0]\n",
    "            max_salary = salary[1]\n",
    "        else:\n",
    "            salary_type = 'Negotiable'\n",
    "        key_skills = []\n",
    "        for i in job_details.find_all('div', class_ = 'card-item'):\n",
    "            for j in i.find_all('ul', class_ = 'list mb-0'):\n",
    "                for x in j.find_all('li'):\n",
    "                    key_skills.append(x.text.strip().replace('  ', '')+'\\n')\n",
    "                    if len(key_skills) == 5:\n",
    "                        break\n",
    "        description = job_details.find('p', class_ = 'card-item').text.strip()\n",
    "        job_description = iterutils.chunked(description,120)\n",
    "        \n",
    "        temp = {\n",
    "                'Job Title': job_title,\n",
    "                'Description': description,\n",
    "                'Job Sector': job_sector,\n",
    "                'Job Type' : job_type,\n",
    "                'Required Skills': key_skills,\n",
    "                'Industry' : industry,\n",
    "                'Location': location,\n",
    "                'Salary Type' : salary_type,\n",
    "                'Min Salary': min_salary,\n",
    "                'Max Salary': min_salary\n",
    "                }\n",
    "            \n",
    "        data.append(temp)\n",
    "        data_length = len(data)\n",
    "        print(f\"{data_length} ====> {temp['Job Title']}\")\n",
    "            \n",
    "    if monsterindia_responce_checker_in >= 1:\n",
    "        print(f'Start scraping from current page againg and after csv created just delete some duplicate jobs in range-{page*25} to last scraped job {data_length}')\n",
    "        break\n",
    "    print(f'All job on page-{page} scraped...\\n')\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating CSV file to store scrapped data\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(filename,index=False,header=True)\n",
    "data_list = pd.read_csv(filename).values.tolist()\n",
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posting Function defined\n",
    "\n",
    "def posting_failed(filename_failed, try_, posting_start, last_posting):\n",
    "\n",
    "    #Reading CSV file\n",
    "    data_list = pd.read_csv(filename_failed).values.tolist()\n",
    "\n",
    "    if posting_start <= 2:\n",
    "        posting_start = 0\n",
    "    elif posting_start > 2:\n",
    "        posting_start = posting_start - 2\n",
    "\n",
    "    if try_ != 0:\n",
    "        last_posting = len(data_list) + 1\n",
    "    last_posting = last_posting - 1\n",
    "\n",
    "\n",
    "    #Variables created for Un-posted Job record\n",
    "    post_no = 0\n",
    "    post_count = 0\n",
    "    # post_record = {}\n",
    "    fail_count = 0\n",
    "    fail_countt = 0\n",
    "    fail_record = {}\n",
    "    fail_index = []\n",
    "\n",
    "    #Posting Jobs form CSV file\n",
    "    for i in range(posting_start, last_posting):            \n",
    "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "        another_options = webdriver.EdgeOptions()                                          #|If you want to work with chromedriver, simply comment this line\n",
    "        #another_options = webdriver.ChromeOptions()                                       #|If you want to work with chromedriver, simply remove comment symbol(#) of this line\n",
    "        another_options.add_argument('--start-maximized')\n",
    "        another_options.add_argument('--incognito')\n",
    "        another_options.add_argument('--disable-gpu')\n",
    "        another_options.add_argument('--disable-geolocation')\n",
    "        another_options.add_argument('--disable-extensions')\n",
    "        \n",
    "        try:\n",
    "            another_driver = webdriver.Edge(EdgeChromiumDriverManager().install())             #|If you want to work with chromedriver, simply comment this line\n",
    "            #another_driver = webdriver.Chrome(ChromeDriverManager().install())                #|If you want to work with chromedriver, simply remove comment symbol(#) of this line\n",
    "        except:\n",
    "            print(f\"Your Connection is Lost\")\n",
    "            fail_countt = -1\n",
    "            print(\"Cell Exicution Terminated...\")\n",
    "            break        \n",
    "        \n",
    "        # another_driver.minimize_window()\n",
    "        \n",
    "        try:\n",
    "            another_driver.get('https://japanplacements.com')\n",
    "            time.sleep(2)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(f\"Error Occured because to OXY-MARS website isn't responding\")\n",
    "            fail_countt = -1\n",
    "            print(\"Cell Exicution Terminated...\")\n",
    "            break\n",
    "\n",
    "        # login section\n",
    "        driver.find_element_by_class_name(\"careerfy-open-signup-tab jobsearch-open-signin-tab\")\n",
    "        driver.click()\n",
    "        driver.find_element_by_name('pt_user_login').send_keys(email_address)\n",
    "        driver.find_element_by_name('pt_user_pass').send_keys('!primeHP')\n",
    "        driver.find_element_by_class_name('jobsearch-login-submit-btn').click()\n",
    "        time.sleep(7)\n",
    "        driver.find_element_by_xpath('//*[@id=\"careerfy-header\"]/div[2]/div/div/div/a').click()\n",
    "        time.sleep(7)\n",
    "        #driver.get('https://japanplacements.com/post-new-job/')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # job title\n",
    "        another_driver.find_element_by_id('ad-posting-title').send_keys(data_list[i][0])\n",
    "        # job description\n",
    "        if 10000 < len(data_list[i][6]):\n",
    "            data_list[i][6] = data_list[i][6][:9950]\n",
    "            pos = data_list[i][6].rfind('.')\n",
    "            data_list[i][6] = data_list[i][6][:pos+1]\n",
    "        data_list[i][6] = data_list[i][6].replace('\t',' ')\n",
    "        another_driver.switch_to.frame(\"job_detail_ifr\") # we need to change to frame in order to see the html elements/attribute\n",
    "        another_driver.find_element_by_id('tinymce').send_keys(data_list[i][6]) # enter full description\n",
    "\n",
    "        another_driver.switch_to.default_content() # switch to main page \n",
    "\n",
    "        # #email address\n",
    "        # another_driver.find_element_by_name('reg_user_email').send_keys(email_address)\n",
    "        \n",
    "        # #username   \n",
    "        # another_driver.find_element_by_name('reg_user_uname').send_keys(username)\n",
    "        \n",
    "        #company name\n",
    "        #another_driver.find_element_by_name('pt_user_organization').send_keys(company_name)\n",
    "\n",
    "        #job sector\n",
    "        sector = identify_job_sector(data_list[i][8])\n",
    "        another_driver.find_element_by_id('job-sector-selectized').send_keys(sector)\n",
    "        another_driver.find_element_by_id('job-sector-selectized').send_keys(Keys.ENTER)\n",
    "\n",
    "        #job type\n",
    "        another_driver.find_element_by_id('job-type-selectized').send_keys(data_list[i][7])\n",
    "        another_driver.find_element_by_id('job-type-selectized').send_keys(Keys.ENTER)\n",
    "    \n",
    "        #skills here\n",
    "        data_list[i][9] = data_list[i][9].replace('\t','')\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-skills\"]/li/input').send_keys(data_list[i][9])\n",
    "\n",
    "        # salary\n",
    "        another_driver.find_element_by_name('job_salary').send_keys(data_list[i][10])\n",
    "        another_driver.find_element_by_name('job_max_salary').send_keys(data_list[i][10])\n",
    "\n",
    "        #other info\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[1]/div/div/div[1]/input').send_keys('Others')\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[1]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "        \n",
    "        # experiece\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[2]/div/div/div[1]/input').send_keys(data_list[i][5])\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[2]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "\n",
    "        #gender\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[3]/div/div/div[1]/input').send_keys('Any')\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[3]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "        \n",
    "        #qualifications \n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[4]/div/div/div[1]/input').send_keys(\"Degree Bachelor\")\n",
    "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[4]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
    "\n",
    "        try:\n",
    "            #country   \n",
    "            another_driver.find_element_by_xpath('//*[@id=\"countryId-selectized\"]').send_keys('India')\n",
    "            another_driver.find_element_by_xpath('//*[@id=\"countryId-selectized\"]').send_keys(Keys.ENTER)\n",
    "            time.sleep(14)\n",
    "            \n",
    "            #state    \n",
    "            another_driver.find_element_by_xpath('//*[@id=\"stateId-selectized\"]').send_keys(data_list[i][2]) \n",
    "            another_driver.find_element_by_xpath('//*[@id=\"stateId-selectized\"]').send_keys(Keys.ENTER)\n",
    "            time.sleep(7)\n",
    "\n",
    "            #city\n",
    "            if data_list[i][2] == 'Delhi':\n",
    "                pass\n",
    "            elif data_list[i][2] == 'Orrisa':\n",
    "                pass\n",
    "            elif data_list[i][2] == 'Jammu Kashmir':\n",
    "                pass\n",
    "            else:    \n",
    "                another_driver.find_element_by_xpath('//*[@id=\"cityId-selectized\"]').send_keys(data_list[i][4])\n",
    "                another_driver.find_element_by_xpath('//*[@id=\"cityId-selectized\"]').send_keys(Keys.ENTER)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        CITY=data_list[i][3]\n",
    "        complete_address = f'{CITY}, India'\n",
    "        if 'India' in CITY:\n",
    "            complete_address = CITY\n",
    "        another_driver.find_element_by_name('jobsearch_field_location_address').send_keys(complete_address)\n",
    "\n",
    "        try:\n",
    "            another_driver.find_element_by_name('terms_cond_check').click()\n",
    "            time.sleep(2)\n",
    "            another_driver.find_element_by_css_selector('input[type=\"submit\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "            print(f\"Error Occured because to OXY-MARS website isn't responding\")\n",
    "            fail_countt = -1\n",
    "            print(\"Cell Exicution Terminated...\")\n",
    "            break\n",
    "\n",
    "        time.sleep(14)\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(another_driver.page_source, 'html.parser')\n",
    "            confirmation = (soup.find('div', class_ = 'jobsearch-employer-confitmation').h2).text.replace(' ','')\n",
    "            if confirmation == 'Thankyouforsubmitting':\n",
    "                post_no = post_no + 1\n",
    "                print(f'{post_no}.Posting job of row no.{i+2} from CSV file done...')\n",
    "                post_count = post_count+1\n",
    "                # post_record[i+2] = data_list[i][0]\n",
    "            else:\n",
    "                print(f'Job of row-{i+2} {data_list[i][0]} in CSV file is not posted. Just wait, posting next job********in*******')\n",
    "                fail_index.append(i)\n",
    "                fail_record[i+2] = data_list[i][0]\n",
    "                fail_count = fail_count+1   \n",
    "        except AttributeError:\n",
    "            print(f'Job of row-{i+2} {data_list[i][0]} in CSV file is not posted. Just wait, posting next job********out********')\n",
    "            fail_index.append(i)\n",
    "            fail_record[i+2] = data_list[i][0]\n",
    "            fail_count = fail_count+1\n",
    "\n",
    "        #another_driver.quit()\n",
    "\n",
    "    print(f'\\nTotal No of Jobs Posted - {post_count}')\n",
    "    #print('list of Jobs Successfully Posted', post_record)\n",
    "    print(f'Total No of Jobs Failed to Post - {fail_count}')\n",
    "    print('list of Jobs Failed to get Posted', fail_record)\n",
    "    data_list_for_failed = pd.read_csv(filename_failed)\n",
    "\n",
    "    failed_jobs = []\n",
    "    for j in fail_index:\n",
    "        failed_jobs_dict = data_list_for_failed.iloc[j].to_dict()\n",
    "        failed_jobs.append(failed_jobs_dict)\n",
    "    if fail_count > 0: \n",
    "        fd = pd.DataFrame(failed_jobs)\n",
    "        filename_failed = 'failed_jobs_' + str(try_) + '.csv'\n",
    "        fd.to_csv(filename_failed,index=False,header=True)\n",
    "    elif fail_countt == -1:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"\\nCongratulations, you did posted all jobs from MonsterIndia for your Given Task/Company\")\n",
    "\n",
    "    posting_start = 2\n",
    "    return fail_count, filename_failed, fail_countt, posting_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Driver [C:\\Users\\ap788\\.wdm\\drivers\\edgedriver\\win64\\95.0.1020.53\\msedgedriver.exe] found in cache\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: MicrosoftEdge=95.0.1020.53)\nStacktrace:\nBacktrace:\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B6291D2+447442]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B256EF3+950483]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B247348+886056]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2481E5+889797]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B249D79+896857]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B242BDA+867770]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2C0F96+1384822]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2AD08F+1303151]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B28334F+1131823]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B28445F+1136191]\n\tMicrosoft::Applications::Events::EventProperty::~EventProperty [0x00007FF67B33CA9D+14365]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2EDEE5+1568965]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B4FAC69+2617]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2EEEAE+1573006]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA9C8+60360]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA224+58404]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA076+57974]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5FA76C+256364]\n\tBaseThreadInitThunk [0x00007FFBDBA77034+20]\n\tRtlUserThreadStart [0x00007FFBDC722651+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23100/3998217625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposting_failed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_failed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposting_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_posting\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mfilename_failed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mposting_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23100/3645786738.py\u001b[0m in \u001b[0;36mposting_failed\u001b[1;34m(filename_failed, try_, posting_start, last_posting)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# login section\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"careerfy-open-signup-tab jobsearch-open-signin-tab\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pt_user_login'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memail_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         )\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1239\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    420\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: MicrosoftEdge=95.0.1020.53)\nStacktrace:\nBacktrace:\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B6291D2+447442]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B256EF3+950483]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B247348+886056]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2481E5+889797]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B249D79+896857]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B242BDA+867770]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2C0F96+1384822]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2AD08F+1303151]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B28334F+1131823]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B28445F+1136191]\n\tMicrosoft::Applications::Events::EventProperty::~EventProperty [0x00007FF67B33CA9D+14365]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2EDEE5+1568965]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B4FAC69+2617]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67B2EEEAE+1573006]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA9C8+60360]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA224+58404]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5CA076+57974]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67B5FA76C+256364]\n\tBaseThreadInitThunk [0x00007FFBDBA77034+20]\n\tRtlUserThreadStart [0x00007FFBDC722651+33]\n"
     ]
    }
   ],
   "source": [
    "#                          ***Posting function is getting call from this cell....***\n",
    "\n",
    "\n",
    "filename_failed = filename\n",
    "dlst = pd.read_csv(filename_failed).values.tolist()\n",
    "last_posting = len(dlst) + 1\n",
    "#Do not change lines above\n",
    "\n",
    "            \n",
    "posting_start = 2               #Enter row no. to start posting from that row of CSV file(defaultly give 2, as first job is at row-2 in CSV)\n",
    "#last_posting = 10              #If you want to give end range for posting, remove '#' symbol on starting of this line & replace 10 to certain number jobs...\n",
    "                                    #give number like till which job/row(including) in csv you want to post in one exicution.\n",
    "\n",
    "\n",
    "#Calling Function\n",
    "for i in range(0, 10):\n",
    "\n",
    "    p = posting_failed(filename_failed, i, posting_start, last_posting)\n",
    "    filename_failed = p[1]\n",
    "    posting_start = p[3]\n",
    "    if p[0] == 0:\n",
    "        break\n",
    "    elif p[2] == -1:\n",
    "        break\n",
    "    elif i == 9:\n",
    "        print('We tried 10 times, if you seeing this msg. You need to contact Group/Team leader')\n",
    "        break\n",
    "    print(f\"\\n\\nTrying {i+2}th time Again for all failed jobs\\n\\n\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Edge(EdgeChromiumDriverManager().install())\n",
    "driver.get(\"https://japanplacements.com/\")\n",
    "driver.maximize_window()\n",
    "link = driver.find_element_by_link_text(\"Login\")\n",
    "link.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16336/3312567050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for i, j in range(5), range(5):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fab145c62319e31a41c9a6790a7fad7c720880be9303f3e3ea8a2856d3d97e4d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
